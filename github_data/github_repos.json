[
  {
    "name": "Mailspring-Plugin-Starter",
    "url": "https://github.com/davidatoms/Mailspring-Plugin-Starter",
    "description": "A template for kicking off your very own Mailspring plugin!",
    "type": "fork",
    "updated_at": "2025-06-16T05:23:21Z",
    "readme": "## Mailspring Plugin Starter\n\nThis folder contains a sample plugin for Mailspring that adds components to the composer's \"action bar\" and the right sidebar shown in the message viewer.\n\n## Building a Plugin\n\nCopy or symlink this project into `~/Library/Application Support/Mailspring/packages` on MacOS, or the corresponding location on Windows and Linux. (You can find this directory by going to _Developer > Show Mailsync Logs_ in Mailspring).\n\nYou can rename this directory and change the `name` field of `package.json` to rename your plugin. Keep in mind that plugins are like node modules and the names cannot contain spaces!\n\nTo get started, run `npm install` in your plugin's directory and then `npm run-script build` to compile the `src` folder into the `lib` folder. To see your changes in Mailspring, quit and relaunch the app OR open the developer tools and reload the app's main window.\n\nFor documentation of how to build plugins, check out [https://foundry376.github.io/Mailspring/](https://foundry376.github.io/Mailspring/) for (slightly outdated) information and also have a look at the many plugins that ship within the core app: [https://github.com/Foundry376/Mailspring/tree/master/app/internal_packages](https://github.com/Foundry376/Mailspring/tree/master/app/internal_packages). Some of the bundled plugins, like `composer-translate`, `composer-templates`, and `phishing-detection` are great starting points!\n\n## Shipping a Plugin\n\nMailspring does not transpile the source code in your plugin when it runs - it expects that your JSX files, TypeScript, etc. has already been converted to plain ES2017 JavaScript. To give your plugin to other people, you should commit the `lib` directory so that they can download the repository, put it in place via the \"Install a Plugin...\" menu item in Mailspring, and be done.\n\n## Future\n\nIn the next year or so, we'll be launching a first-class \"plugin gallery\" in Mailspring and formalizing the development and release processes. Right now, building a plugin using TypeScript is a real pain because Mailspring - while written in TypeScript - doesn't export the types for you to build against. Stay tuned!\n\n## A note about Node Modules\n\nRight now, if your plugin depends on external node modules (say, a CSV parser like `node-csv`), you'd need to package up a zip file that contained those modules already installed in `node_modules`, or have your users run `npm install`. In the future, Mailspring will run npm install for you.\n\nHowever, we do not plan to support Mailspring plugins that require _native_ node modules - the kind that compile C++ or C code into platform-specific binaries. It's really hard to ship all of the tooling required to build these reliably, pre-packing them for each platform is annoying, and they often break when the node / nan versions change. Be warned! (An example of this would be `sqlite` or something like `node-addressbook`. You can often tell if a module contains native code if there is a `binding.gyp` file or if the install process takes a while and calls out to `make` or `gcc`.)\n"
  },
  {
    "name": "circuit-tracer-exploration",
    "url": "https://github.com/davidatoms/circuit-tracer-exploration",
    "description": null,
    "type": "original",
    "updated_at": "2025-06-16T04:31:45Z",
    "readme": "# circuit-tracer-exploration"
  },
  {
    "name": "swiftmouse",
    "url": "https://github.com/davidatoms/swiftmouse",
    "description": "A shortcat like app for keyboard-based mouse navigation on Linux",
    "type": "fork",
    "updated_at": "2025-06-14T06:12:22Z",
    "readme": ""
  },
  {
    "name": "davidatoms",
    "url": "https://github.com/davidatoms/davidatoms",
    "description": "Github Readme Profile",
    "type": "original",
    "updated_at": "2025-06-10T12:02:35Z",
    "readme": "# David Adams Automatic GitHub Readme\n\n<p align=\"left\"><b>Last Updated:</b> <!-- last_updated starts -->June 10, 2025 at 12:02 (161/365 (0.441) of the year)<!-- last_updated ends -->\n</p>\n\n<p align=\"left\">\n  <img src=\"https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white\" />\n  <img src=\"https://img.shields.io/badge/Go-00ADD8?style=flat&logo=go&logoColor=white\" />\n  <img src=\"https://img.shields.io/badge/Rust-000000?style=flat&logo=rust&logoColor=white\" />\n  <img src=\"https://img.shields.io/badge/React-20232A?style=flat&logo=react&logoColor=61DAFB\" />\n  <img src=\"https://img.shields.io/badge/Bash-4EAA25?style=flat&logo=gnu-bash&logoColor=white\" />\n</p>\n\nI am passionate about a better future through innovation and investments. \n\n## Recent Repositories\n<!-- recent_repos starts -->\n[**vert**](https://github.com/davidatoms/vert) - VERT is a file conversion utility that converts files on your device using WebAssembly, eliminating the need for cloud services and ensuring privacy.\n\n[**rybbit**](https://github.com/davidatoms/rybbit) - Rybbit is an open-source, privacy-focused web and product analytics platform offering comprehensive insights without user tracking or cookies, ensuring GDPR and CCPA compliance.\n\n[**davidatoms**](https://github.com/davidatoms/davidatoms) - This repository showcases David Adams' coding projects, professional profile, and documentation generated using Anthropic's Claude AI and GitHub Actions to update the README dynamically.\n\n[**browser-use**](https://github.com/davidatoms/browser-use) - Browser-use enables AI agents to control web browsers, automating tasks like shopping, job applications, and content creation through a user-friendly Python library.\n\n[**dgm**](https://github.com/davidatoms/dgm) - The Darwin G\u00f6del Machine (DGM) is an open-ended self-improving system that iteratively modifies its own codebase through machine learning, empirically validating each change using coding benchmarks, improving its ability to improve itself.\n\n[**neuronpedia**](https://github.com/davidatoms/neuronpedia) - Neuronpedia is an open-source interpretability platform that enables exploring, visualizing, and interacting with AI model neurons and their representations.\n\n[**opencage-geocoding-mcp**](https://github.com/davidatoms/opencage-geocoding-mcp) - This repository provides an MCP server that enables geocoding capabilities using the OpenCage geocoding API, allowing conversion between addresses and geographic coordinates.\n\n[**Warp**](https://github.com/davidatoms/Warp) - This is an issues-only repository for Warp, a modern GPU-accelerated terminal with AI and integrated team knowledge, compatible with various shells on macOS, Linux, and Windows.\n\n[**hacks-leaks-and-revelations**](https://github.com/davidatoms/hacks-leaks-and-revelations) - This repository contains code and resources accompanying the book \"Hacks, Leaks, and Revelations,\" guiding readers through acquiring datasets, using command-line tools, Python programming, and exploring real-world case studies.\n\n[**voxelize**](https://github.com/davidatoms/voxelize) - Voxelize is a multiplayer, super-fast voxel engine that runs in your browser, allowing you to create and explore voxel worlds with custom blocks and physics.\n<!-- recent_repos ends -->\n\n<br>\n\n![Star this repository](https://img.shields.io/badge/Star%20this%20repository-FFDD00?style=flat&logo=github&logoColor=white)\n![Profile Views](https://komarev.com/ghpvc/?username=davidatoms&style=flat&color=blue&label=Views)\n"
  },
  {
    "name": "vert",
    "url": "https://github.com/davidatoms/vert",
    "description": "The next-generation file converter. Open source, fully local* and free forever.",
    "type": "fork",
    "updated_at": "2025-06-05T01:36:09Z",
    "readme": "<p align=\"center\">\n  <img src=\"https://github.com/user-attachments/assets/bf441748-0ec5-4c8a-b3e5-11301ee3f0bd\" alt=\"VERT's logo\" height=\"100\">\n</p>\n<h1 align=\"center\"><a href=\"https://vert.sh\">VERT.sh</a></h1>\n\nVERT is a file conversion utility that uses WebAssembly to convert files on your device instead of a cloud. Check out the live instance at [vert.sh](https://vert.sh).\n\nVERT is built in Svelte and TypeScript.\n\n## Features\n\n- Convert files directly on your device using WebAssembly *\n- No file size limits\n- Supports multiple file formats\n- User-friendly interface built with Svelte\n\n<sup>* Non-local video conversion is available with our official instance, but the [daemon](https://github.com/VERT-sh/vertd) is easily self-hostable to maintain privacy and fully local functionality.</sup>\n\n## Getting Started\n\n### Prerequisites\n\nMake sure you have the following installed:\n\n- [Bun](https://bun.sh/)\n\n### Installation\n```sh\n# Clone the repository\ngit clone https://github.com/VERT-sh/vert.git\ncd vert\n# Install dependencies\nbun i\n```\n\n### Running Locally\n\nTo run the project locally, run `bun dev`.\n\nThis will start a development server. Open your browser and navigate to `http://localhost:5173` to see the application.\n\n### Building for Production\n\nBefore building for production, make sure you create a `.env` file in the root of the project with the following content:\n\n```sh\nPUB_HOSTNAME=example.com # change to your domain, only gets used for Plausible (for now)\nPUB_PLAUSIBLE_URL=https://plausible.example.com # can be empty if not using Plausible\nPUB_ENV=production # \"production\", \"development\" or \"nightly\"\nPUB_VERTD_URL=https://vertd.vert.sh # default vertd instance\n```\n\nTo build the project for production, run `bun run build`\n\nThis will build the site to the `build` folder. You should then use a web server like [nginx](https://nginx.org) to serve the files inside that folder.\n\nIf using nginx, you can use the [nginx.conf](./nginx.conf) file as a starting point. Make sure you keep [cross-origin isolation](https://web.dev/articles/cross-origin-isolation-guide) enabled.\n\n### With Docker\n\nClone the repository, then build a Docker image with:\n```shell\n$ docker build -t vert-sh/vert \\\n\t--build-arg PUB_ENV=production \\\n\t--build-arg PUB_HOSTNAME=vert.sh \\\n\t--build-arg PUB_PLAUSIBLE_URL=https://plausible.example.com \\\n\t--build-arg PUB_VERTD_URL=https://vertd.vert.sh .\n```\n\nYou can then run it by using:\n```shell\n$ docker run -d \\\n\t--restart unless-stopped \\\n\t-p 3000:80 \\\n\t--name \"vert\" \\\n\tvert-sh/vert\n```\n\nThis will do the following:\n- Use the previously built image as the container `vert`, in detached mode\n- Continuously restart the container until manually stopped\n- Map `3000/tcp` (host) to `80/tcp` (container)\n\nWe also have a [`docker-compose.yml`](./docker-compose.yml) file available. Use `docker compose up` if you want to start the stack, or `docker compose down` to bring it down. You can pass `--build` to `docker compose up` to rebuild the Docker image (useful if you've changed any of the environment variables) as well as `-d` to start it in detached mode. You can read more about Docker Compose in general [here](https://docs.docker.com/compose/intro/compose-application-model/).\n\nWhile there's an image you can pull instead of cloning the repo and building the image yourself, you will not be able to update any of the environment variables (e.g. `PUB_PLAUSIBLE_URL`) as they're baked directly into the image and not obtained during runtime. If you're okay with this, you can simply run this command instead:\n```shell\n$ docker run -d \\\n\t--restart unless-stopped \\\n\t-p 3000:80 \\\n\t--name \"vert\" \\\n\tghcr.io/vert-sh/vert:latest\n```\n\n## License\n\nThis project is licensed under the AGPL-3.0 License, please see the [LICENSE](LICENSE) file for details.\n"
  },
  {
    "name": "rybbit",
    "url": "https://github.com/davidatoms/rybbit",
    "description": "\ud83d\udc38 Rybbit - open-source and privacy-friendly alternative to Google Analytics that is 10x more intuitive.",
    "type": "fork",
    "updated_at": "2025-06-05T00:37:35Z",
    "readme": "<p align=\"center\">\n  <img src=\"https://github.com/user-attachments/assets/1425302a-40b6-4d97-bf4b-89927ea93fb9\" height=\"250\" style=\"border-radius: 5%;\">\n    <h1 align=\"center\">\n        Rybbit Analytics \n    </h1>\n    <p align=\"center\">Open Source Web & Product Analytics</p>\n\n<p align=\"center\">\n    <a href=\"https://rybbit.io\" target=\"_blank\">Website</a> |\n    <a href=\"https://demo.rybbit.io/1\" target=\"_blank\">Demo</a> |\n    <a href=\"https://rybbit.io/docs\" target=\"_blank\">Documentation</a> |\n    <a href=\"https://discord.gg/DEhGb4hYBj\" target=\"_blank\">Discord</a> |\n    <a href=\"https://github.com/rybbit-io/rybbit?tab=AGPL-3.0-1-ov-file\" target=\"_blank\">License (AGPL-3)</a> |\n    <a href=\"https://github.com/rybbit-io/contribute.md\" target=\"_blank\">Contribute</a>\n</p>\n\n</p>\n\n<a href=\"https://rybbit.io/\" target=\"_blank\">Rybbit</a> is the modern open source and privacy friendly alternative to Google Analytics. It takes only a couple minutes to setup and is super intuitive to use.\n\n<p align=\"center\">\n  <strong><a href=\"https://demo.rybbit.io/1\">\ud83d\udd0d View Live Demo</a></strong> - See Rybbit running on a real-life production site with over a million visits a month.\n</p>\n\n<hr>\n\n## \ud83d\ude80 Getting Started\n\nThere are two ways to start using Rybbit:\n\n| Option                                                  | Description                                                   |\n| ------------------------------------------------------- | ------------------------------------------------------------- |\n| **[Hosted Service](https://rybbit.io)**                 | Free tier available - the fastest way to get started          |\n| **[Self-Hosting](https://rybbit.io/docs/self-hosting)** | Deploy and manage Rybbit on your own VPS for complete control |\n\n\ud83d\udcda Explore our [documentation](https://rybbit.io/docs) to learn more about installation, configuration, and usage.\n\n<hr>\n\n## \u2728 Key Features\n\n- All key web analytics metrics including sessions, unique users, pageviews, bounce rate, session duration\n- No cookies or user tracking - GDPR & CCPA compliant\n- Customizable goals. retention, user journeys, and funnels dashboards\n- Advanced filtering across 15+ dimensions\n- Custom events with JSON properties\n- Live sessions dashboard\n- 3 level location tracking (country -> region -> city) + advanced map visualizations\n- Real time dashboard\n- Support for organizations and unlimited number of sites\n\n<hr>\n\n## \ud83d\udcca Dashboard Preview\n\n### Main\n\n![image](https://github.com/user-attachments/assets/7f2d3b79-90b6-496b-9b47-373ba1c62a7e)\n\n### Realtime\n\n![image](https://github.com/user-attachments/assets/54996620-4eff-4ecc-9135-10ce21483f6a)\n\n### Sessions\n\n![image](https://github.com/user-attachments/assets/b87769f3-650d-4069-9e18-5d59e41a175b)\n\n### Journeys\n\n![image](https://github.com/user-attachments/assets/890f9de8-3025-4962-91c5-5a1b2ddf0d82)\n\n### Map\n\n![image](https://github.com/user-attachments/assets/b1f7be89-ec8d-4ccc-9a87-45b0fb31d3a1)\n\n### Funnels\n\n![image](https://github.com/user-attachments/assets/bad9e37c-1ff6-49b4-9285-6dde7f90051f)\n\n### Goals\n\n![image](https://github.com/user-attachments/assets/60503585-5daf-4cfe-927e-4e149749f538)\n\n<hr>\n\n## \u2b50 Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=rybbit-io/rybbit&type=Date)](https://www.star-history.com/#rybbit-io/rybbit&Date)\n"
  },
  {
    "name": "browser-use",
    "url": "https://github.com/davidatoms/browser-use",
    "description": "\ud83c\udf10 Make websites accessible for AI agents. Automate tasks online with ease.",
    "type": "fork",
    "updated_at": "2025-06-01T06:12:49Z",
    "readme": "<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./static/browser-use-dark.png\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./static/browser-use.png\">\n  <img alt=\"Shows a black Browser Use Logo in light color mode and a white one in dark color mode.\" src=\"./static/browser-use.png\"  width=\"full\">\n</picture>\n\n<h1 align=\"center\">Enable AI to control your browser \ud83e\udd16</h1>\n\n[![GitHub stars](https://img.shields.io/github/stars/gregpr07/browser-use?style=social)](https://github.com/gregpr07/browser-use/stargazers)\n[![Discord](https://img.shields.io/discord/1303749220842340412?color=7289DA&label=Discord&logo=discord&logoColor=white)](https://link.browser-use.com/discord)\n[![Cloud](https://img.shields.io/badge/Cloud-\u2601\ufe0f-blue)](https://cloud.browser-use.com)\n[![Documentation](https://img.shields.io/badge/Documentation-\ud83d\udcd5-blue)](https://docs.browser-use.com)\n[![Twitter Follow](https://img.shields.io/twitter/follow/Gregor?style=social)](https://x.com/gregpr07)\n[![Twitter Follow](https://img.shields.io/twitter/follow/Magnus?style=social)](https://x.com/mamagnus00)\n[![Weave Badge](https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_T5Pvn3UBswTHIsN1dWS3voPg%2F881458615&labelColor=#EC6341)](https://app.workweave.ai/reports/repository/org_T5Pvn3UBswTHIsN1dWS3voPg/881458615)\n\n\ud83c\udf10 Browser-use is the easiest way to connect your AI agents with the browser.\n\n\ud83d\udca1 See what others are building and share your projects in our [Discord](https://link.browser-use.com/discord)! Want Swag? Check out our [Merch store](https://browsermerch.com).\n\n\ud83c\udf24\ufe0f Skip the setup - try our <b>hosted version</b> for instant browser automation! <b>[Try the cloud \u2601\ufe0e](https://cloud.browser-use.com)</b>.\n\n# Quick start\n\nWith pip (Python>=3.11):\n\n```bash\npip install browser-use\n```\n\nFor memory functionality (requires Python<3.13 due to PyTorch compatibility):  \n\n```bash\npip install \"browser-use[memory]\"\n```\n\nInstall the browser:\n```bash\nplaywright install chromium --with-deps --no-shell\n```\n\nSpin up your agent:\n\n```python\nimport asyncio\nfrom dotenv import load_dotenv\nload_dotenv()\nfrom browser_use import Agent\nfrom langchain_openai import ChatOpenAI\n\nasync def main():\n    agent = Agent(\n        task=\"Compare the price of gpt-4o and DeepSeek-V3\",\n        llm=ChatOpenAI(model=\"gpt-4o\"),\n    )\n    await agent.run()\n\nasyncio.run(main())\n```\n\nAdd your API keys for the provider you want to use to your `.env` file.\n\n```bash\nOPENAI_API_KEY=\nANTHROPIC_API_KEY=\nAZURE_OPENAI_ENDPOINT=\nAZURE_OPENAI_KEY=\nGOOGLE_API_KEY=\nDEEPSEEK_API_KEY=\nGROK_API_KEY=\nNOVITA_API_KEY=\n```\n\nFor other settings, models, and more, check out the [documentation \ud83d\udcd5](https://docs.browser-use.com).\n\n### Test with UI\n\nYou can test browser-use using its [Web UI](https://github.com/browser-use/web-ui) or [Desktop App](https://github.com/browser-use/desktop).\n\n### Test with an interactive CLI\n\nYou can also use our `browser-use` interactive CLI (similar to `claude` code):\n\n```bash\npip install browser-use[cli]\nbrowser-use\n```\n\n# Demos\n\n<br/><br/>\n\n[Task](https://github.com/browser-use/browser-use/blob/main/examples/use-cases/shopping.py): Add grocery items to cart, and checkout.\n\n[![AI Did My Groceries](https://github.com/user-attachments/assets/a0ffd23d-9a11-4368-8893-b092703abc14)](https://www.youtube.com/watch?v=L2Ya9PYNns8)\n\n<br/><br/>\n\nPrompt: Add my latest LinkedIn follower to my leads in Salesforce.\n\n![LinkedIn to Salesforce](https://github.com/user-attachments/assets/50d6e691-b66b-4077-a46c-49e9d4707e07)\n\n<br/><br/>\n\n[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/use-cases/find_and_apply_to_jobs.py): Read my CV & find ML jobs, save them to a file, and then start applying for them in new tabs, if you need help, ask me.'\n\nhttps://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04\n\n<br/><br/>\n\n[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/browser/real_browser.py): Write a letter in Google Docs to my Papa, thanking him for everything, and save the document as a PDF.\n\n![Letter to Papa](https://github.com/user-attachments/assets/242ade3e-15bc-41c2-988f-cbc5415a66aa)\n\n<br/><br/>\n\n[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/custom-functions/save_to_file_hugging_face.py): Look up models with a license of cc-by-sa-4.0 and sort by most likes on Hugging face, save top 5 to file.\n\nhttps://github.com/user-attachments/assets/de73ee39-432c-4b97-b4e8-939fd7f323b3\n\n<br/><br/>\n\n## More examples\n\nFor more examples see the [examples](examples) folder or join the [Discord](https://link.browser-use.com/discord) and show off your project. You can also see our [`awesome-prompts`](https://github.com/browser-use/awesome-prompts) repo for prompting inspiration.\n\n# Vision\n\nTell your computer what to do, and it gets it done.\n\n## Roadmap\n\n### Agent\n\n- [ ] Improve agent memory to handle +100 steps\n- [ ] Enhance planning capabilities (load website specific context)\n- [ ] Reduce token consumption (system prompt, DOM state)\n\n### DOM Extraction\n\n- [ ] Enable detection for all possible UI elements\n- [ ] Improve state representation for UI elements so that all LLMs can understand what's on the page\n\n### Workflows\n\n- [ ] Let user record a workflow - which we can rerun with browser-use as a fallback\n- [ ] Make rerunning of workflows work, even if pages change\n\n### User Experience\n\n- [ ] Create various templates for tutorial execution, job application, QA testing, social media, etc. which users can just copy & paste.\n- [ ] Improve docs\n- [ ] Make it faster\n\n### Parallelization\n\n- [ ] Human work is sequential. The real power of a browser agent comes into reality if we can parallelize similar tasks. For example, if you want to find contact information for 100 companies, this can all be done in parallel and reported back to a main agent, which processes the results and kicks off parallel subtasks again.\n\n\n## Contributing\n\nWe love contributions! Feel free to open issues for bugs or feature requests. To contribute to the docs, check out the `/docs` folder.\n\n## Local Setup\n\nTo learn more about the library, check out the [local setup \ud83d\udcd5](https://docs.browser-use.com/development/local-setup).\n\n\n`main` is the primary development branch with frequent changes. For production use, install a stable [versioned release](https://github.com/browser-use/browser-use/releases) instead.\n\n---\n\n## Swag\n\nWant to show off your Browser-use swag? Check out our [Merch store](https://browsermerch.com). Good contributors will receive swag for free \ud83d\udc40.\n\n## Citation\n\nIf you use Browser Use in your research or project, please cite:\n\n```bibtex\n@software{browser_use2024,\n  author = {M\u00fcller, Magnus and \u017duni\u010d, Gregor},\n  title = {Browser Use: Enable AI to control your browser},\n  year = {2024},\n  publisher = {GitHub},\n  url = {https://github.com/browser-use/browser-use}\n}\n```\n\n <div align=\"center\"> <img src=\"https://github.com/user-attachments/assets/06fa3078-8461-4560-b434-445510c1766f\" width=\"400\"/> \n \n[![Twitter Follow](https://img.shields.io/twitter/follow/Gregor?style=social)](https://x.com/gregpr07)\n[![Twitter Follow](https://img.shields.io/twitter/follow/Magnus?style=social)](https://x.com/mamagnus00)\n \n </div>\n\n<div align=\"center\">\nMade with \u2764\ufe0f in Zurich and San Francisco\n </div>\n"
  },
  {
    "name": "dgm",
    "url": "https://github.com/davidatoms/dgm",
    "description": "Darwin G\u00f6del Machine: Open-Ended Evolution of Self-Improving Agents",
    "type": "fork",
    "updated_at": "2025-05-30T03:09:44Z",
    "readme": "<h1 align=\"center\">\n    Darwin G\u00f6del Machine:<br/>Open-Ended Evolution of Self-Improving Agents\n</h1>\n\n<p align=\"center\">\n  <a href=\"https://github.com/jennyzzt/dgm/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=for-the-badge\"></a>\n  <a href=\"https://arxiv.org/abs/2505.22954\"><img src=\"https://img.shields.io/badge/arXiv-2505.22954-b31b1b.svg?logo=arxiv&style=for-the-badge\"></a>\n  <a href=\"https://sakana.ai/dgm/\"><img src=\"https://img.shields.io/badge/-Blog-%238D6748?style=for-the-badge&logo=Website&logoColor=white\"></a>\n  <a href=\"https://x.com/SakanaAILabs/status/1928272612431646943\"><img src=\"https://img.shields.io/badge/twitter-%230077B5.svg?&style=for-the-badge&logo=twitter&logoColor=white&color=00acee\"></a>\n  <a href=\"https://drive.google.com/drive/folders/1Kcu9TbIa9Z50pJ7S6hH9omzzD1pxIYZC?usp=sharing\"><img src=\"https://img.shields.io/badge/Experiment%20Logs-4285F4?style=for-the-badge&logo=googledrive&logoColor=white\"></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"./misc/overview.gif\" width=\"100%\" height=\"auto\" />\n</p>\n\nRepository for **Darwin G\u00f6del Machine (DGM)**, a novel self-improving system that iteratively modifies its own code (thereby also improving its ability to modify its own codebase) and empirically validates each change using coding benchmarks.\n\n<p align=\"center\">\n<img src=\"./misc/conceptual.svg\"/></a><br>\n</p>\n\n\n## Setup\n```bash\n# API keys, add to ~/.bashrc\nexport OPENAI_API_KEY='...'\nexport ANTHROPIC_API_KEY='...'\n```\n\n```bash\n# Verify that Docker is properly configured in your environment.\ndocker run hello-world\n \n# If a permission error occurs, add the user to the Docker group\nsudo usermod -aG docker $USER\nnewgrp docker\n```\n\n```bash\n# Install dependencies\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n\n# Optional: for running analysis\nsudo apt-get install graphviz graphviz-dev\npip install -r requirements_dev.txt\n```\n\n```bash\n# Clone SWE-bench\ncd swe_bench\ngit clone https://github.com/princeton-nlp/SWE-bench.git\ncd SWE-bench\ngit checkout dc4c087c2b9e4cefebf2e3d201d27e36\npip install -e .\ncd ../../\n\n# Prepare Polyglot\n# Make sure git is properly configured in your environment with username and email\npython polyglot/prepare_polyglot_dataset.py\n```\n\n## Running the DGM\n```bash\npython DGM_outer.py\n```\nBy default, outputs will be saved in the `output_dgm/` directory.\n\n## File Structure\n- `analysis/` scripts used for plotting and analysis\n- `initial/` SWE-bench logs and performance of the initial agent\n- `initial_polyglot/` Polyglot logs and performance of the initial agent\n- `swe_bench/` code needed for SWE-bench evaluation\n- `polyglot/` code needed for Polyglot evaluation\n- `prompts/` prompts used for foundation models\n- `tests/` tests for the DGM system\n- `tools/` tools available to the foundation models\n- `coding_agent.py` main implementation of the initial coding agent\n- `DGM_outer.py` entry point for running the DGM algorithm\n\n## Logs from Experiments\nThis [google drive folder](https://drive.google.com/drive/folders/1Kcu9TbIa9Z50pJ7S6hH9omzzD1pxIYZC?usp=sharing) contains all the foundation model output logs from the experiments shown in the paper.\n\n## Safety Consideration\n> [!WARNING]  \n> This repository involves executing untrusted, model-generated code. We strongly advise users to be aware of the associated safety risks. While it is highly unlikely that such code will perform overtly malicious actions under our current settings and with the models we use, it may still behave destructively due to limitations in model capability or alignment. By using this repository, you acknowledge and accept these risks.\n\n## Acknowledgement\n\nThe evaluation framework implementations are based on the [SWE-bench](https://github.com/swe-bench/SWE-bench) and [polyglot-benchmark](https://github.com/Aider-AI/polyglot-benchmark) repositories.\n\n## Citing\nIf you find this project useful, please consider citing:\n```bibtex\n@article{zhang2025darwin,\n  title={Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents},\n  author={Zhang, Jenny and Hu, Shengran and Lu, Cong and Lange, Robert and Clune, Jeff},\n  journal={arXiv preprint arXiv:2505.22954},\n  year={2025}\n}\n```\n"
  },
  {
    "name": "neuronpedia",
    "url": "https://github.com/davidatoms/neuronpedia",
    "description": "open source interpretability platform \ud83e\udde0",
    "type": "fork",
    "updated_at": "2025-05-30T02:06:57Z",
    "readme": "<p align=\"center\">\n  <a href=\"https://github.com/hijohnnylin/neuronpedia\">\n    <img src=\"https://github.com/user-attachments/assets/9bcea0bf-4fa9-401d-bb7a-d031a4d12636\" alt=\"Splash GIF\"/>\n  </a>\n\n<h3 align=\"center\"><a href=\"https://neuronpedia.org\">neuronpedia.org \ud83e\udde0\ud83d\udd0d</a></h3>\n\n  <p align=\"center\">\n    open source interpretability platform\n    <br />\n    <sub>\n    <strong>api \u00b7 steering \u00b7 activations \u00b7 autointerp \u00b7 scoring \u00b7 inference \u00b7 search \u00b7 filter \u00b7 dashboards \u00b7 benchmarks \u00b7 cossim \u00b7 umap \u00b7 embeds \u00b7 probes \u00b7 saes \u00b7 lists \u00b7 exports \u00b7 uploads</strong>\n    </sub>\n  </p>\n</p>\n\n<p align=\"center\" style=\"color: #cccccc;\">\n  <a href=\"https://github.com/hijohnnylin/neuronpedia/blob/main/LICENSE\"><img height=\"20px\" src=\"https://img.shields.io/badge/license-MIT-yellow.svg\" alt=\"MIT\"></a>\n  <a href=\"https://status.neuronpedia.org\"><img height=\"20px\" src=\"https://uptime.betterstack.com/status-badges/v2/monitor/1roih.svg\" alt=\"Uptime\"></a>\n  <a href=\"https://join.slack.com/t/opensourcemechanistic/shared_invite/zt-2o756ku1c-_yKBeUQMVfS_p_qcK6QLeA\"><img height=\"20px\" src=\"https://img.shields.io/badge/slack-purple?logo=slack&logoColor=white\" alt=\"Slack\"></a>\n  <a href=\"mailto:johnny@neuronpedia.org\"><img height=\"20px\" src=\"https://img.shields.io/badge/contact-blue.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PGcgaWQ9IlNWR1JlcG9fYmdDYXJyaWVyIiBzdHJva2Utd2lkdGg9IjAiPjwvZz48ZyBpZD0iU1ZHUmVwb190cmFjZXJDYXJyaWVyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiPjwvZz48ZyBpZD0iU1ZHUmVwb19pY29uQ2FycmllciI+IDxwYXRoIGQ9Ik00IDcuMDAwMDVMMTAuMiAxMS42NUMxMS4yNjY3IDEyLjQ1IDEyLjczMzMgMTIuNDUgMTMuOCAxMS42NUwyMCA3IiBzdHJva2U9IiNmZmZmZmYiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIj48L3BhdGg+IDxyZWN0IHg9IjMiIHk9IjUiIHdpZHRoPSIxOCIgaGVpZ2h0PSIxNCIgcng9IjIiIHN0cm9rZT0iI2ZmZmZmZiIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiPjwvcmVjdD4gPC9nPjwvc3ZnPg==\" alt=\"Email\"></a>\n  <a href=\"https://neuronpedia.org/blog\"><img height=\"20px\" src=\"https://img.shields.io/badge/blog-10b981.svg\" alt=\"blog\"></a>\n  <a href=\"https://neuronpedia.org\"><img height=\"20px\" src=\"https://img.shields.io/badge/website-gray.svg\" alt=\"website\"></a>\n  <a href=\"https://www.every.org/decode-research\"><img height=\"20px\" src=\"https://img.shields.io/badge/sponsor-green.svg\" alt=\"Sponsor\"></a>\n\n</p>\n\n- [about neuronpedia](#about-neuronpedia)\n- [instant start - vercel deploy](#instant-start---vercel-deploy)\n- [quick start - local webapp + demo environment](#quick-start---local-webapp--demo-environment)\n- [setting up your local environment](#setting-up-your-local-environment)\n  - [\"i want to use a local database / import more neuronpedia data\"](#i-want-to-use-a-local-database--import-more-neuronpedia-data)\n  - [\"i want to do webapp (frontend + api) development\"](#i-want-to-do-webapp-frontend--api-development)\n  - [\"i want to run/develop inference locally\"](#i-want-to-rundevelop-inference-locally)\n  - ['i want to run/develop autointerp locally\\`](#i-want-to-rundevelop-autointerp-locally)\n  - ['i want to do high volume autointerp explanations'](#i-want-to-do-high-volume-autointerp-explanations)\n  - ['i want to generate my own dashboards/data and add it to neuronpedia'](#i-want-to-generate-my-own-dashboardsdata-and-add-it-to-neuronpedia)\n- [architecture](#architecture)\n  - [requirements](#requirements)\n  - [services](#services)\n    - [services are standalone apps](#services-are-standalone-apps)\n    - [service-specific documentation](#service-specific-documentation)\n  - [openapi schema](#openapi-schema)\n  - [monorepo directory structure](#monorepo-directory-structure)\n- [security](#security)\n- [contact / support](#contact--support)\n- [contributing](#contributing)\n- [appendix](#appendix)\n    - ['make' commands reference](#make-commands-reference)\n    - [import data into your local database](#import-data-into-your-local-database)\n    - [why an openai api key is needed for search explanations](#why-an-openai-api-key-is-needed-for-search-explanations)\n\n<!-- # ultra-quick start: one-click deploy on vercel\nTODO, after making repo public -->\n\n# about neuronpedia\n\ncheck out our [blog post](https://www.neuronpedia.org/blog/neuronpedia-is-now-open-source) about Neuronpedia, why we're open sourcing it, and other details. there's also a [tweet thread](https://x.com/neuronpedia/status/1906793456879775745) with quick demos.\n\n**feature overview**\n\na diagram showing the main features of neuronpedia as of march 2025.\n![neuronpedia-features](https://github.com/user-attachments/assets/13e07a93-e046-4e1c-b670-2d26d251d55d)\n\n# instant start - vercel deploy\n\nclick the `Deploy` button to instantly deploy a custom neuronpedia. a [free vercel account](https://vercel.com/signup) is required.\n\n<p align=\"left\">\n  <a href=\"https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fhijohnnylin%2Fneuronpedia&env=NEXT_PUBLIC_SITE_NAME_VERCEL_DEPLOY&envDescription=***Your%20Custom%20Website%20Name.%20For%20example%3A%20PuppyNeurons***&root-directory=apps/webapp&build-command=npx%20prisma%20generate%20%26%26%20npm%20run%20build%3Ademo&project-name=my-neuronpedia&repository-name=my-neuronpedia&demo-title=Neuronpedia&demo-description=Deploy%20your%20own%20custom%20Neuronpedia%20%F0%9F%9A%80%F0%9F%A7%A0%F0%9F%A7%90&demo-url=https%3A%2F%2Fneuronpedia.org\">\n    <img src=\"https://vercel.com/button\" width=\"160\" alt=\"Deploy with Vercel\"/>\n  </a>\n</p>\n\nhere's how easy it is to deploy a \"PuppyNeurons\" fork of Neuronpedia:\n\nhttps://github.com/user-attachments/assets/707deaed-02b4-442b-8c1f-bf44d193b9fa\n\n# quick start - local webapp + demo environment\n\n#### what this does\n\nthis sets up the webapp (frontend + api) locally, and connects to a public remote demo database and public inference servers\n\n#### what you'll get\n\nafter following the quick start, you will be able to use neuronpedia for some sources/SAEs we have preloaded in `gpt2-small` and `gemma-2-2b/-it`.\n\n> \u26a0\ufe0f **warning:** since you are connecting to a public, read-only demo database, you will not be able to add new data immediately. you will need to follow [subsequent steps](#i-want-to-use-my-own-database--import-more-neuronpedia-data) to configure your own database that you can write to.\n\n#### steps\n\n1. install [docker desktop (UI)](https://docs.docker.com/desktop/) or [docker engine (no UI)](https://docs.docker.com/engine/), and launch it.\n2. generate your local `.env`\n   ```\n   make init-env\n   ```\n3. build the webapp (this will take ~10 min the first time)\n   ```\n   make webapp-demo-build\n   ```\n4. bring up the webapp\n   ```\n   make webapp-demo-run\n   ```\n5. once everything is up, open [localhost:3000](http://localhost:3000) to load the home page.\n6. your local instance is connected to the remote demo database and inference servers, with the following SAEs/sources data available:\n\n| model                          | source/sae                            | comment                                        |\n| ------------------------------ | ------------------------------------- | ---------------------------------------------- |\n| `gpt2-small`                   | `res-jb`, all layers                  | a small starter SAE set                        |\n| `gemma-2-2b` / `gemma-2-2b-it` | `gemmascope-res-16k`, all layers      | the SAEs used in the Gemma Scope demo          |\n| `deepseek-r1-distill-llama-8b` | `llamascope-slimpj-res-32k`, layer 15 | SAE for a reasoning model, trained by OpenMOSS |\n\n7. example things you can do (links work after `make webapp-demo-run`)\n\n   i. steering - [steer gpt2-small on cats](http://localhost:3000/gpt2-small/steer?source=10-res-jb&index=16899&strength=40)\n\n   ii. activation tests/search - [test activation for a gemma-2-2b feature](http://localhost:3000/gemma-2-2b/20-gemmascope-res-16k/502?defaulttesttext=what's%20the%20deal%20with%20airplane%20food%3F)\n\n   iii. search by explanation, [if you configured](<(#why-an-openai-api-key-is-needed-for-search-explanations)>) an `OPENAI_API_KEY` - [search for parrots features](http://localhost:3000/search-explanations/?q=parrots)\n\n   iv. browse dashboards - [a parrot feature](http://localhost:3000/gpt2-small/11-res-jb/23687)\n\n   v. run the [gemma-scope demo](http://localhost:3000/gemma-scope#main)\n\n8. now that we've set up a local webapp that's usable, this is a good time to quickly review neuronpedia's [simple architecture](#architecture) and its [individual services](#services), so that you can get a better understanding of what you'll set up later. then, keep going to [setting up your local environment](#setting-up-your-local-environment).\n\n> \ud83d\udd25 **pro-tip:** see all the available `make` commands by running `make help`\n\n# setting up your local environment\n\nonce you've played around with the demo, you will start running into limitations, like having a limited number of models/SAEs to use, or not being able to generate new explanations. this is because the public demo database is read-only.\n\nideally, you will probably eventually want to do all of the sub-sections below, so you can have everything running locally. however, you may only be interested in specific parts of neuronpedia to start:\n\n1. if you want to jump into developing webapp frontend or api with the demo environment, follow [webapp dev](#i-want-to-do-webapp-frontend--api-development)\n2. if you want to start loading more sources/data and relying on your own local database, follow [local database](#i-want-to-use-a-local-database--import-more-neuronpedia-data)\n\n> \ud83d\udd25 **pro-tip:** neuronpedia is configured for AI agent development. here's an example using a [single prompt](https://github.com/hijohnnylin/neuronpedia/blob/main/apps/experiments/steerify/README.md#claude-code-prompt) to build a custom app (Steerify) using Neuronpedia's inference server as a backend:\n\nhttps://github.com/user-attachments/assets/bc82f88b-8155-4c1d-948a-ea5d987ae0f8\n\n## \"i want to use a local database / import more neuronpedia data\"\n\n#### what this does + what you'll get\n\nrelying on the demo environment means you are limited to read-only access to a specific set of SAEs. these steps show you how to configure and connect to your own local database. you can then download sources/SAEs of your choosing:\n\nhttps://github.com/user-attachments/assets/d7fbb46e-8522-4f98-aa08-21c6529424af\n\n> \u26a0\ufe0f **warning:** your database will start out empty. you will need to use the admin panel to [import sources/data](#import-data-into-your-local-database) (activations, explanations, etc).\n\n> \u26a0\ufe0f **warning:** the local database environment does not have any inference servers connected, so you won't be able to do activation testing, steering, etc initially. you will need to [configure a local inference instance]().\n\n#### steps\n\n1. build the webapp\n   ```\n   make webapp-localhost-build\n   ```\n2. bring up the webapp\n   ```\n   make webapp-localhost-run\n   ```\n3. go to [localhost:3000](http://localhost:3000) to see your local webapp instance, which is now connected to your local database\n4. see the `warnings` above for caveats, and `next steps` to finish setting up\n\n#### next steps\n\n1. [click here](#import-data-into-your-local-database) for how to import data into your local database (activations, explanations, etc), because your local database will be empty to start\n2. [click here](#i-want-to-rundevelop-inference-locally) for how to bring up a local `inference` service for the model/source/SAE you're working with\n\n## \"i want to do webapp (frontend + api) development\"\n\n#### what this does\n\nthe webapp builds you've been doing so far are _production builds_, which are slow to build, and fast to run. since they are slow to build and don't have debug information, they are not ideal for development.\n\nthis subsection installs the development build on your local machine (not docker), then mounts the build inside your docker instance.\n\n#### what you'll get\n\nonce you do this section, you'll be able to do local development and quickly see changes that are made, as well as see more informative debug/errors. if you are purely interested in doing frontend/api development for neuronpedia, you don't need to set up anything else!\n\n#### steps\n\n1. install [nodejs](https://nodejs.org) via [node version manager](https://github.com/nvm-sh/nvm)\n   ```\n   make install-nodejs\n   ```\n2. install the webapp's dependencies\n   ```\n   make webapp-localhost-install\n   ```\n3. run the development instance\n   ```\n   make webapp-localhost-dev\n   ```\n4. go to [localhost:3000](http://localhost:3000) to see your local webapp instance\n\n#### doing local webapp development\n\n- **auto-reload**: when you change any files in the `apps/webapp` subdirectory, the `localhost:3000` will automatically reload\n- **install commands**: you do not need to run `make install-nodejs` again, and you only need to run `make webapp-localhost-install` if dependencies change\n\n## \"i want to run/develop inference locally\"\n\n#### what this does + what you'll get\n\nonce you start using a local environment, you won't be connected to the demo environment's inference instances. this subsection shows you how to run an inference instance locally so you can do things like steering, activation testing, etc on the sources/SAEs you've downloaded.\n\n> \u26a0\ufe0f **warning:** for the local environment, we only support running one inference server at a time. this is because you are unlikely to be running multiple models simultaneously on one machine, as they are memory and compute intensive.\n\n#### steps\n\n1. ensure you have [installed poetry](https://python-poetry.org/docs/#installation)\n2. install the inference server's dependencies\n   ```\n   make inference-localhost-install\n   ```\n3. build the image, picking the correct command based on if the machine has CUDA or not:\n   ```\n   # CUDA\n   make inference-localhost-build-gpu USE_LOCAL_HF_CACHE=1\n   ```\n   ```\n   # no CUDA\n   make inference-localhost-build USE_LOCAL_HF_CACHE=1\n   ```\n   > \u27a1\ufe0f The [`USE_LOCAL_HF_CACHE=1` flag](https://github.com/hijohnnylin/neuronpedia/pull/89) mounts your local HuggingFace cache at `${HOME}/.cache/huggingface/hub:/root/.cache/huggingface/hub`. If you wish to create a new cache in your container instead, you can omit this flag here and in the next step.\n4. run the inference server, using the `MODEL_SOURCESET` argument to specify the `.env.inference.[model_sourceset]` file you're loading from. for this example, we will run `gpt2-small`, and load the `res-jb` sourceset/SAE set, which is configured in the `.env.inference.gpt2-small.res-jb` file. you can see the other [pre-loaded inference configs](#pre-loaded-inference-server-configurations) or [create your own config](#making-your-own-inference-server-configurations) as well.\n\n   ```\n   # CUDA\n   make inference-localhost-dev-gpu \\\n        MODEL_SOURCESET=gpt2-small.res-jb \\\n        USE_LOCAL_HF_CACHE=1\n\n   # no CUDA\n   make inference-localhost-dev \\\n        MODEL_SOURCESET=gpt2-small.res-jb \\\n        USE_LOCAL_HF_CACHE=1\n   ```\n\n5. wait for it to load (first time will take longer). when you see `Initialized: True`, the local inference server is now ready on `localhost:5002`\n\n#### using the inference server\n\nto interact with the inference server, you have a few options - note that this will only work for the model / selected source you have loaded:\n\n1.  load the webapp with the [local database setup](#i-want-to-use-a-local-database--import-more-neuronpedia-data), then using the model / selected source as you would normally do on neuronpedia.\n2.  use the pre-generated inference python client at `packages/python/neuronpedia-inference-client` (set environment variable `INFERENCE_SERVER_SECRET` to `public`, or whatever it's set to in `.env.localhost` if you've changed it)\n3.  use the openapi spec, located at `schemas/openapi/inference-server.yaml` to make calls with any client of your choice.\n4.  [TODO #1](https://github.com/hijohnnylin/neuronpedia/issues/1): Use a documentation generator to make a simple tester-server that can be activated with `make doc-inference-localhost`\n\n#### pre-loaded inference server configurations\n\nwe've provided some pre-loaded inference configs as examples of how to load a specific model and sourceset for inference. view them by running `make inference-list-configs`:\n\n```\n$ make inference-list-configs\n\nAvailable Inference Configurations (.env.inference.*)\n================================================\n\ndeepseek-r1-distill-llama-8b.llamascope-slimpj-res-32k\n    Model: meta-llama/Llama-3.1-8B\n    Source/SAE Sets: '[\"llamascope-slimpj-res-32k\"]'\n    make inference-localhost-dev MODEL_SOURCESET=deepseek-r1-distill-llama-8b.llamascope-slimpj-res-32k\n\ngemma-2-2b-it.gemmascope-res-16k\n    Model: gemma-2-2b-it\n    Source/SAE Sets: '[\"gemmascope-res-16k\"]'\n    make inference-localhost-dev MODEL_SOURCESET=gemma-2-2b-it.gemmascope-res-16k\n\ngpt2-small.res-jb\n    Model: gpt2-small\n    Source/SAE Sets: '[\"res-jb\"]'\n    make inference-localhost-dev MODEL_SOURCESET=gpt2-small.res-jb\n```\n\n#### making your own inference server configurations\n\nlook at the `.env.inference.*` files for examples on how to make these inference server configurations.\n\nthe `MODEL_ID` is the model id from the [transformerlens model table](https://transformerlensorg.github.io/TransformerLens/generated/model_properties_table.html) and each of `SAE_SETS` is the text after the layer number and hyphen in a neuronpedia source ID - for example, if you have a neuronpedia feature at url `http://neuronpedia.org/gpt2-small/0-res-jb/123`, the `0-res-jb` is the source ID, and the item in the `SAE_SETS` is `res-jb`. This example matches the `.env.inference.gpt2-small.res-jb` file exactly.\n\nyou can find neuronpedia source IDs in the saelens [pretrained saes yaml file](https://github.com/jbloomAus/SAELens/blob/main/sae_lens/pretrained_saes.yaml) or by clicking into models in the [neuronpedia datasets exports](https://neuronpedia-datasets.s3.us-east-1.amazonaws.com/index.html?prefix=v1/) directory.\n\n**using models not officially supported by transformerlens**\nlook at the `.env.inference.deepseek-r1-distill-llama-8b.llamascope-slimpj-res-32k` to see an example of how to load a model not officially supported by transformerlens. this is mostly for swapping in weights of a distilled/fine-tuned model.\n\n**loading non-saelens sources/SAEs**\n\n- [TODO #2](https://github.com/hijohnnylin/neuronpedia/issues/2) document how to load SAEs/sources that are not in saelens pretrained yaml\n\n#### doing local inference development\n\n- **schema-driven development**: to add new endpoints or change existing endpoints, you will need to start by updating the openapi schemas, then generating clients from that, then finally updating the actual inference and webapp code. for details on how to do this, see the [openapi readme: making changes to the inference server](schemas/README.md#making-changes-to-the-inference-server)\n- **no auto-reload**: when you change any files in the `apps/inference` subdirectory, the inference server will _NOT_ automatically reload, because server reloads are slow: they reload the model and all sources/SAEs. if you want to enable autoreload, then append `AUTORELOAD=1` to the `make inference-localhost-dev` call, like so:\n  ```\n  make inference-localhost-dev \\\n       MODEL_SOURCESET=gpt2-small.res-jb \\\n       AUTORELOAD=1\n  ```\n\n## 'i want to run/develop autointerp locally`\n\nthis section is under construction.\n\n- check out the [autointerp readme](apps/autointerp/README.md)\n- [TODO](https://github.com/hijohnnylin/neuronpedia/issues/5) instructions for setting up autointerp server locally\n- TODO - look at the `autointerp` service in [docker-compose.yaml](docker-compose.yaml)\n- schema-driven development: [openapi readme: making changes to the autointerp server](schemas/README.md#making-changes-to-the-autointerp-server)\n\n## 'i want to do high volume autointerp explanations'\n\nthis section is under construction.\n\n- use EleutherAI's [Delphi library](https://github.com/EleutherAI/delphi)\n- for OpenAI's autointerp, use [utils/neuronpedia_utils/batch-autointerp.py](utils/neuronpedia_utils/batch-autointerp.py)\n\n## 'i want to generate my own dashboards/data and add it to neuronpedia'\n\nthis section is under construction.\n\n[TODO: simplify generation + upload of data to neuronpedia](https://github.com/hijohnnylin/neuronpedia/issues/46)\n\n[TODO: neuronpedia-utils should use poetry](https://github.com/hijohnnylin/neuronpedia/issues/43)\n\nin this example, we will generate dashboards/data for an [SAELens](https://github.com/jbloomAus/SAELens)-compatible SAE, and upload it to our own Neuronpedia instance.\n\n1. ensure you have [Poetry installed](https://python-poetry.org/docs/)\n2. [upload](https://github.com/jbloomAus/SAELens/blob/main/tutorials/uploading_saes_to_huggingface.ipynb) your SAELens-compatible source/SAE to HuggingFace.\n   > Example\n   > \u27a1\ufe0f [https://huggingface.co/chanind/gemma-2-2b-batch-topk-matryoshka-saes-w-32k-l0-40](https://huggingface.co/chanind/gemma-2-2b-batch-topk-matryoshka-saes-w-32k-l0-40)\n3. clone SAELens locally.\n   ```\n   git clone https://github.com/jbloomAus/SAELens.git\n   ```\n4. open your cloned SAELens and edit the file `sae_lens/pretrained_saes.yaml`. add a new entry at the bottom, based on the template below (see comments for how to fill it out):\n   > Example\n   > \u27a1\ufe0f [https://github.com/jbloomAus/SAELens/pull/455/files](https://github.com/jbloomAus/SAELens/pull/455/files)\n   ```\n   gemma-2-2b-res-matryoshka-dc:                 # a unique ID for your set of SAEs\n     conversion_func: null                       # null if your SAE config is already compatible with SAELens\n     links:                                      # optional links\n       model: https://huggingface.co/google/gemma-2-2b\n     model: gemma-2-2b                           # transformerlens model id - https://transformerlensorg.github.io/TransformerLens/generated/model_properties_table.html\n     repo_id: chanind/gemma-2-2b-batch-topk-matryoshka-saes-w-32k-l0-40  # the huggingface repo path\n     saes:\n     - id: blocks.0.hook_resid_post                 # an id for this SAE\n       path: standard/blocks.0.hook_resid_post      # the path in the repo_id to the SAE\n       l0: 40.0\n       neuronpedia: gemma-2-2b/0-matryoshka-res-dc  # what you expect the neuronpedia URI to be - neuronpedia.org/[this_slug]. should be [model_id]/[layer]-[identical_slug_for_this_sae_set]\n     - id: blocks.1.hook_resid_post                 # more SAEs in this SAE set\n       path: standard/blocks.1.hook_resid_post\n       l0: 40.0\n       neuronpedia: gemma-2-2b/1-matryoshka-res-dc  # note that this is identical to the entry above, except 1 instead of 0 for the layer\n     - [...]\n   ```\n5. clone [SAEDashboard](https://github.com/jbloomAus/SAEDashboard.git) locally.\n   ```\n   git clone https://github.com/jbloomAus/SAEDashboard.git\n   ```\n6. configure your cloned `SAEDashboard` to use your cloned modified `SAELens`, instead of the one in production\n   ```\n   cd SAEDashboard                    # set directory\n   poetry lock && poetry install      # install dependencies\n   poetry remove sae-lens             # remove production dependency\n   poetry add PATH/TO/CLONED/SAELENS  # set local dependency\n   ```\n7. generate dashboards for the SAE. this will take from 30 min to a few hours, depending on your hardware and size of model.\n\n   ```\n   cd SAEDashboard                    # set directory\n   rm -rf cached_activations          # clear old cached data\n\n   # start the generation. details for each argument (full details: https://github.com/jbloomAus/SAEDashboard/blob/main/sae_dashboard/neuronpedia/neuronpedia_runner_config.py)\n   #     - sae-set = should match the unique ID for the set from pretrained_saes.yaml\n   #     - sae-path = should match the id for the sae in from pretrained_saes.yaml\n   #     - np-set-name = should match the [identical_slug_for_this_sae_set] for the sae.neuronpedia from pretrained_saes.yaml\n   #     - dataset-path = the huggingface dataset to use for generating activations. usually you want to use the same dataset the model was trained on.\n   #     - output-dir = the output directory of the dashboard data\n   #     - n-prompts = number of activation texts to test from the dataset\n   #     - n-tokens-in-prompt, n-features-per-batch, n-prompts-in-forward-pass = keep these at 128\n   poetry run neuronpedia-runner \\\n        --sae-set=\"gemma-2-2b-res-matryoshka-dc\" \\\n        --sae-path=\"blocks.12.hook_resid_post\" \\\n        --np-set-name=\"matryoshka-res-dc\" \\\n        --dataset-path=\"monology/pile-uncopyrighted\" \\\n        --output-dir=\"neuronpedia_outputs/\" \\\n        --sae_dtype=\"float32\" \\\n        --model_dtype=\"bfloat16\" \\\n        --sparsity-threshold=1 \\\n        --n-prompts=24576 \\\n        --n-tokens-in-prompt=128 \\\n        --n-features-per-batch=128 \\\n        --n-prompts-in-forward-pass=128\n   ```\n\n8. convert these dashboards for import into neuronpedia\n   ```\n   cd neuronpedia/utils/neuronpedia-utils          # get into this current repository's util directory\n   python convert-saedashboard-to-neuronpedia.py   # start guided conversion script. follow the steps.\n   ```\n9. once dashboard files are generated for neuronpedia, upload these to the global Neuronpedia S3 bucket - currently you need to [contact us](mailto:johnny@neuronpedia.org) to do this.\n10. from a localhost instance, [import your data](#i-want-to-use-a-local-database--import-more-neuronpedia-data)\n\n# architecture\n\nhere's how the services/scripts connect in neuronpedia. it's easiest to read this diagram by starting at the image of the laptop (\"User\").\n\n![architecture diagram](architecture.png)\n\n## requirements\n\nyou can run neuronpedia on any cloud and on any modern OS. neuronpedia is designed to avoid vendor lock-in. these instructions were written for and tested on macos 15 (sequoia), so you may need to repurpose commands for windows/ubuntu/etc. at least 16GB ram is recommended.\n\n## services\n\n| name       | description                                                                                                                                                  | powered by                            |\n| ---------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------- |\n| webapp     | serves the neuronpedia.org frontend and [the api](neuronpedia.org/api-doc)                                                                                   | [next.js](https://nextjs.org) / react |\n| database   | stores features, activations, explanations, users, lists, etc                                                                                                | postgres                              |\n| inference  | [support server] steering, activation testing, search via inference, topk, etc. a separate instance is required for each model you want to run inference on. | python / torch                        |\n| autointerp | [support server] auto-interp explanations and scoring, using eleutherAI's [delphi](https://github.com/EleutherAI/delphi) (formerly `sae-auto-interp`)        | python                                |\n\n### services are standalone apps\n\nby design, each service can be run independently as a standalone app. this is to enable extensibility and forkability.\n\nfor example, if you like the neuronpedia webapp frontend but want to use a different API for inference, you can do that! just ensure your alternative inference server supports the `schema/openapi/inference-server.yaml` spec, and/or that you modify the neuronpedia calls to inference under `apps/webapp/lib/utils`.\n\n### service-specific documentation\n\nthere are draft `README`s for each specific app/service under `apps/[service]`, but they are heavily WIP. you can also check out the `Dockerfile` under the same directory to build your own images.\n\n## openapi schema\n\nfor services to communicate with each other in a typed and consistent way, we use openapi schemas. there are some exceptions - for example, streaming is not offically supported by the openapi spec. however, even in that case, we still try our best to define a schema and use it.\n\nespecially for inference and autointerp server development, it is critical to understand and use the instructions under the [openapi readme](schemas/README.md).\n\nopenapi schemas are located under `/schemas`. we use openapi generators to generate clients in both typescript and python.\n\n## monorepo directory structure\n\n`apps` - the three neuronpedia services: webapp, inference, and autointerp. most of the code is here.\n`schemas` - the openapi schemas. to make changes to inference and autointerp endpoints, first make changes to their schemas - see details in the [openapi readme](schemas/README.md).\n`packages` - clients generated from the `schemas` using generator tools. you will mostly not need to manually modify these files.\n`utils` - various utilities that help do offline processing, like high volume autointerp, or generating dashboards, or exporting data.\n\n# security\n\nplease report vulnerabilities to [johnny@neuronpedia.org](mailto:johnny@neuronpedia.org).\n\nwe don't currently have an official bounty program, but we'll try our best to give compensation based on the severity of the vulnerability - though it's likely we will not able able to offer awards for any low-severity vulnerabilities.\n\n# contact / support\n\n- slack: [join #neuronpedia](https://join.slack.com/t/opensourcemechanistic/shared_invite/zt-2o756ku1c-_yKBeUQMVfS_p_qcK6QLeA)\n- email: [johnny@neuronpedia.org](mailto:johnny@neuronpedia.org)\n- issues: [github issues](https://github.com/hijohnnylin/neuronpedia/issues)\n\n# contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n\n# appendix\n\n### 'make' commands reference\n\nyou can view all available `make` commands and brief descriptions of them by running `make help`\n\n### import data into your local database\n\nif you set up your own database, it will start out empty - no features, explanations, activations, etc. to load this data, there's a built-in `admin panel` where you can download this data for SAEs (or \"sources\") of your choosing.\n\n> \u26a0\ufe0f **warning:** the admin panel is finicky and does not currently support resuming imports. if an import is interrupted, you must manually click `re-sync`. the admin panel currently does not check if your download is complete or missing parts - it is up to you to check if the data is complete, and if not, to click `re-sync` to re-download the entire dataset.\n\n> \u2139\ufe0f **recommendation:** when importing data, start with just one source (like `gpt2-small`@`10-res-jb`) instead of downloading everything at once. This makes it easier to verify the data imported correctly and lets you start using neuronpedia faster.\n\nthe instructions below demonstrate how to download the `gpt2-small`@`10-res-jb` SAE data.\n\n1. navigate to [localhost:3000/admin](http://localhost:3000/admin).\n2. scroll down to `gpt2-small`, and expand `res-jb` with the `\u25b6`.\n3. click `Download` next to `10-res-jb`.\n4. wait patiently - this can be a _LOT_ of data, and depending on your connection/cpu speed it can take up to 30 minutes or an hour.\n5. once it's done, click `Browse` or use the navbar to try it out: `Jump To`/`Search`/`Steer`.\n6. repeat for other SAE/source data you wish to download.\n\n### why an openai api key is needed for search explanations\n\nin the webapp, the `search explanations` feature requires you to set an `OPENAI_API_KEY`. otherwise you will get no search results.\n\nthis is because the `search explanations` functionality searches for features by semantic similarity. if you search `cat`, it will also return `feline`, `tabby`, `animal`, etc. to do this, it needs to calculate the embedding for your input `cat`. we use openai's embedding api (specifically, `text-embedding-3-large` with `dimension: 256`) to calculate the embeddings.\n"
  },
  {
    "name": "opencage-geocoding-mcp",
    "url": "https://github.com/davidatoms/opencage-geocoding-mcp",
    "description": "MCP server for querying the OpenCage geocoding API from within LLMs",
    "type": "fork",
    "updated_at": "2025-05-27T22:34:08Z",
    "readme": "# OpenCage Geocoding MCP Server\n\nAn MCP (Model Context Protocol) server that provides geocoding capabilities using the [OpenCage geocoding API](https://opencagedata.com/api).\nThis server allows you to convert between addresses and geographic coordinates.\n\n**PLEASE NOTE:** the examples shown here are based on an integration with [claude.ai](https://claude.ai/)'s desktop client. MCP as a concept is supported by other services, but may require a slightly different configuration.\n\n## Features\n\n- **Forward Geocoding**: Convert addresses or place names to coordinates (latitude/longitude)\n- **Reverse Geocoding**: Convert coordinates to addresses\n- **API Status Monitoring**: Check your API usage and rate limits (assuming your penCage account has hard limits).\n\n## Prerequisites\n\n1. **Node.js** (version 20 or higher)\n2. **OpenCage geocoding API Key**: Sign up on [the OpenCage website](https://opencagedata.com/) to get a free-trial geocoding API key\n\n## Installation\n\n1. Clone the repository. Change into the repository directory\n\n```bash\n\ngit clone git@github.com:OpenCageData/opencage-geocoding-mcp.git\n# or\ngit clone https://github.com/OpenCageData/opencage-geocoding-mcp.git\n\ncd opencage-geocoding-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Set your OpenCage geocoding API key as an environment variable:\n\n```bash\nexport OPENCAGE_API_KEY=\"your_opencage_geocoding_api_key_here\"\n```\n\n4. Build the project:\n\n```bash\nnpm run build\n```\n\n## Usage\n\n### Using within Claude Desktop\n\nAdd this configuration to your Claude Desktop config file\n\nOn a Mac the config file should be (`~/Library/Application Support/Claude/claude_desktop_config.json`), but you can also navigate to the file via the menu: `Settings > Developer > Edit Config`\n\n```json\n{\n  \"mcpServers\": {\n    \"opencage-geocoding\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/opencage-geocoding-mcp/build/index.js\"],\n      \"env\": {\n        \"OPENCAGE_API_KEY\": \"your_opencage_geocoding_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\nNote: the first time you run a command you will need to give Claude permission\n\n![Allow external integration](allow-external-integration.png)\n\n### 1. geocode-forward\n\nConvert an address or place name to coordinates and information about that location.\n\n**Parameters:**\n\n- `query` (required): The address or place name to geocode\n- `countrycode` (optional): Restrict to country (ISO 3166-1 alpha-2 code)\n- `bounds` (optional): Bounding box (min_lon,min_lat,max_lon,max_lat)\n- `language` (optional): Language for results (e.g., 'en', 'de', 'fr')\n- `limit` (optional): Max results (1-100, default 10)\n- `no_annotations` (optional): Exclude location annotations\n\n**Example:**\n\n```\nQuery: \"1600 Pennsylvania Avenue, Washington, DC\"\nResult: JSON with coordinates, formatted address, confidence score, address components, annotations\n```\n\n### 2. geocode-reverse\n\nConvert coordinates to an address and information about that location\n\n**Parameters:**\n\n- `latitude` (required): Latitude coordinate (-90 to 90) in decimal format\n- `longitude` (required): Longitude coordinate (-180 to 180) in decimal format\n- `language` (optional): Language for results\n- `no_annotations` (optional): Exclude location annotations\n\n**Example:**\n\n```\nInput: 38.8976, -77.0365\nResult: \"1600 Pennsylvania Avenue NW, Washington, DC 20500, United States of America\"\n```\n\n### 3. get-opencage-info\n\nCheck your current API usage and rate limits.\n**NOTE**: subscription customers do NOT have hard usage limits. See [relevant documentation](https://opencagedata.com/api#rate-limiting).\n\n**Parameters:** None\n\n**Returns:** Information about remaining requests, rate limits, and reset times.\n\n## Available Prompts\n\n### geocoding-assistant\n\nA helpful assistant for geocoding tasks. Provides guidance on using the geocoding tools effectively.\n\n## Error Handling\n\nThe server includes comprehensive error handling:\n\n- Invalid API keys\n- Rate limit exceeded\n- Network errors\n- Invalid coordinates or addresses\n- API service unavailable\n\n## Environment Variables\n\n- `OPENCAGE_API_KEY`: Your OpenCage geocoding API key (required)\n\n## Troubleshooting\n\n1. **\"API key required\" error**: Make sure the env var `OPENCAGE_API_KEY` is set\n2. **\"No results found\"**: Try a more specific or different address format, see [the OpenCage guide to query formatting](https://opencagedata.com/guides/how-to-format-your-geocoding-query)\n3. **Rate limit errors**: Check your API usage with `get-api-status` tool\n4. **Network errors**: Verify internet connection or [the public OpenCage status page](https://status.opencagedata.com/)\n\n## Relevant Links\n\n- [OpenCage homepage](https://opencagedata.com/) - Get your geocoding API key\n- [OpenCage API Documentation](https://opencagedata.com/api) - Full OpenCage geocoding API reference\n- [Model Context Protocol](https://modelcontextprotocol.io/) - Learn more about MCP\n\n### Who is OpenCage GmbH?\n\n<a href=\"https://opencagedata.com\"><img src=\"opencage_logo_300_150.png\"></a>\n\nWe run a worldwide [geocoding API](https://opencagedata.com/api) and [geosearch](https://opencagedata.com/geosearch) service based on open data.\nLearn more [about us](https://opencagedata.com/about).\n\nWe also organize [Geomob](https://thegeomob.com), a series of regular meetups for location based service creators, where we do our best to highlight geoinnovation. If you like geo stuff, you will probably enjoy [the Geomob podcast](https://thegeomob.com/podcast/).\n"
  }
]